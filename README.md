# Spam Detection with Traditional ML vs. Zero-Shot LLM

This project compares traditional machine learning models (Logistic Regression and Naive Bayes) with a zero-shot large language model (LLM) for spam detection. 

I built this project to help one of my online students understand AI better in cyber security using hands on building and comparison approach. Maybe others will find it useful to expand upon also.

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emails.csv
â”œâ”€â”€ ml_models/
â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”œâ”€â”€ logistic_regression.py
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ llm_classifier.py
â”‚   â””â”€â”€ llm_evaluation.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ llm_predictions.csv
â”‚   â”œâ”€â”€ llm_metrics.txt
â”‚   â”œâ”€â”€ llm_confusion_matrix.png
â”‚   â””â”€â”€ llm_roc_curve.png
â””â”€â”€ README.md
```

## ğŸ“Š Dataset

- **Source**: SMS Spam Collection dataset
- **Format**: CSV with columns `text` (message) and `label` (`ham` or `spam`)

## âš™ï¸ Setup

1. Create a virtual environment and install requirements:

```bash
pip install -r requirements.txt
```

2. Create a `.env` file with your Groq API key:

```env
GROQ_API_KEY=your_key_here
```

## ğŸ¤– ML Models

Run the traditional ML classifiers and generate evaluation metrics:

```bash
python ml_models/logistic_regression.py
python ml_models/naive_bayes.py
```

## ğŸ§  LLM Zero-Shot Classification

Run the LLM-based classification (Groq API using LLaMA):

```bash
python llm/llm_classifier.py
```

Then evaluate results:

```bash
python llm/llm_evaluation.py
```

## ğŸ“ˆ Results

LLM and ML model outputs are saved to the `results/` folder, including:

- Accuracy and classification report
- Confusion matrix (PNG)
- ROC curve (PNG)

## ğŸ§ª Next Steps

- Build a Gradio or Streamlit UI for interactive email classification
- Expand dataset and analyze performance across models

---

Â© 2025 Spam Classifier Project â€” Educational Use Only